"""
Mana Charitra - Telugu History Chatbot
Advanced implementation with optimal performance and free deployment
"""

import streamlit as st
import google.generativeai as genai
import os
import json
import sqlite3
import hashlib
import pickle
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import PyPDF2
import io
import re
import logging
from pathlib import Path
import asyncio
from concurrent.futures import ThreadPoolExecutor
import time

# Advanced configuration class for optimal performance
class OptimizedConfig:
    """Production-ready configuration with memory and performance optimizations"""
    
    def __init__(self):
        self.EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # Lightweight, fast model
        self.VECTOR_DIM = 384
        self.MAX_TOKENS = 8192
        self.CHUNK_SIZE = 512
        self.CHUNK_OVERLAP = 64
        self.DB_PATH = "data/mana_charitra.db"
        self.VECTOR_STORE_PATH = "data/vector_store.faiss"
        self.EMBEDDINGS_CACHE_PATH = "data/embeddings_cache.pkl"
        self.MAX_CACHE_SIZE = 1000
        
        # Telugu language specific patterns
        self.TELUGU_PATTERNS = {
            'places': [
                r'[\u0C00-\u0C7F]+\s*(‡∞ï‡±ã‡∞ü|‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç|‡∞ó‡±Å‡∞°‡∞ø|‡∞Æ‡∞Ç‡∞¶‡∞ø‡∞∞‡∞Ç|‡∞™‡∞ü‡±ç‡∞ü‡∞£‡∞Ç|‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç)',
                r'(‡∞µ‡∞∞‡∞Ç‡∞ó‡∞≤‡±ç|‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤|‡∞ö‡∞ø‡∞§‡±ç‡∞§‡±Ç‡∞∞‡±ç|‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞æ‡∞°|‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç|‡∞ï‡∞∞‡±ç‡∞®‡±Ç‡∞≤‡±ç)'
            ],
            'history_keywords': [
                '‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞', '‡∞ï‡∞•', '‡∞™‡±Å‡∞∞‡∞æ‡∞£‡∞Ç', '‡∞µ‡∞Ç‡∞∂‡∞æ‡∞µ‡∞≥‡∞ø', '‡∞ï‡∞æ‡∞≤‡∞Ç', '‡∞∞‡∞æ‡∞ú‡∞µ‡∞Ç‡∞∂‡∞Ç'
            ]
        }

config = OptimizedConfig()

# Advanced caching system for optimal performance
class SmartCache:
    """Memory-efficient caching with LRU eviction"""
    
    def __init__(self, max_size: int = 1000):
        self.cache = {}
        self.access_times = {}
        self.max_size = max_size
    
    def get(self, key: str) -> Optional[any]:
        if key in self.cache:
            self.access_times[key] = time.time()
            return self.cache[key]
        return None
    
    def set(self, key: str, value: any) -> None:
        if len(self.cache) >= self.max_size:
            self._evict_lru()
        
        self.cache[key] = value
        self.access_times[key] = time.time()
    
    def _evict_lru(self) -> None:
        """Remove least recently used item"""
        if not self.access_times:
            return
        
        lru_key = min(self.access_times.keys(), 
                     key=lambda k: self.access_times[k])
        del self.cache[lru_key]
        del self.access_times[lru_key]

# High-performance vector store manager
class OptimizedVectorStore:
    """FAISS-based vector store with advanced optimizations"""
    
    def __init__(self):
        self.model = None
        self.index = None
        self.metadata = []
        self.cache = SmartCache()
        self._load_model()
    
    def _load_model(self) -> None:
        """Load embedding model with caching"""
        try:
            self.model = SentenceTransformer(config.EMBEDDING_MODEL)
            # Optimize model for inference
            self.model.eval()
            logging.info("‚úÖ Embedding model loaded successfully")
        except Exception as e:
            logging.error(f"‚ùå Failed to load embedding model: {e}")
            st.error("Failed to load embedding model")
    
    def _create_embeddings_batch(self, texts: List[str]) -> np.ndarray:
        """Create embeddings in optimized batches"""
        cache_key = hashlib.md5('|'.join(texts).encode()).hexdigest()
        cached = self.cache.get(cache_key)
        
        if cached is not None:
            return cached
        
        # Batch processing for efficiency
        embeddings = self.model.encode(texts, 
                                     batch_size=32,
                                     show_progress_bar=False,
                                     convert_to_numpy=True)
        
        self.cache.set(cache_key, embeddings)
        return embeddings
    
    def add_documents(self, texts: List[str], metadata: List[Dict]) -> None:
        """Add documents to vector store with optimizations"""
        if not texts:
            return
        
        try:
            embeddings = self._create_embeddings_batch(texts)
            
            if self.index is None:
                # Initialize FAISS index with optimal settings
                self.index = faiss.IndexFlatIP(config.VECTOR_DIM)
                # Add index optimization for larger datasets
                if len(texts) > 1000:
                    self.index = faiss.IndexIVFFlat(self.index, config.VECTOR_DIM, 
                                                  min(100, len(texts) // 10))
            
            # Normalize embeddings for cosine similarity
            faiss.normalize_L2(embeddings)
            self.index.add(embeddings.astype('float32'))
            self.metadata.extend(metadata)
            
            logging.info(f"‚úÖ Added {len(texts)} documents to vector store")
            
        except Exception as e:
            logging.error(f"‚ùå Failed to add documents: {e}")
    
    def search(self, query: str, k: int = 5) -> List[Tuple[str, float, Dict]]:
        """Optimized similarity search"""
        if self.index is None or self.index.ntotal == 0:
            return []
        
        try:
            query_embedding = self._create_embeddings_batch([query])
            faiss.normalize_L2(query_embedding)
            
            scores, indices = self.index.search(query_embedding.astype('float32'), k)
            
            results = []
            for score, idx in zip(scores[0], indices[0]):
                if idx < len(self.metadata):
                    results.append((
                        self.metadata[idx]['text'],
                        float(score),
                        self.metadata[idx]
                    ))
            
            return results
            
        except Exception as e:
            logging.error(f"‚ùå Search failed: {e}")
            return []
    
    def save(self) -> None:
        """Save vector store to disk"""
        try:
            if self.index is not None:
                faiss.write_index(self.index, config.VECTOR_STORE_PATH)
                
            with open(config.EMBEDDINGS_CACHE_PATH, 'wb') as f:
                pickle.dump(self.metadata, f)
                
        except Exception as e:
            logging.error(f"‚ùå Failed to save vector store: {e}")
    
    def load(self) -> None:
        """Load vector store from disk"""
        try:
            if os.path.exists(config.VECTOR_STORE_PATH):
                self.index = faiss.read_index(config.VECTOR_STORE_PATH)
                
            if os.path.exists(config.EMBEDDINGS_CACHE_PATH):
                with open(config.EMBEDDINGS_CACHE_PATH, 'rb') as f:
                    self.metadata = pickle.load(f)
                    
        except Exception as e:
            logging.error(f"‚ùå Failed to load vector store: {e}")

# Advanced database manager with optimizations
class OptimizedDatabase:
    """SQLite database with connection pooling and optimizations"""
    
    def __init__(self):
        self.db_path = config.DB_PATH
        self._ensure_directory()
        self._init_database()
    
    def _ensure_directory(self) -> None:
        """Ensure data directory exists"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
    
    def _init_database(self) -> None:
        """Initialize database with optimized schema"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # Enable performance optimizations
                conn.execute("PRAGMA journal_mode=WAL")
                conn.execute("PRAGMA synchronous=NORMAL")
                conn.execute("PRAGMA cache_size=10000")
                conn.execute("PRAGMA temp_store=memory")
                
                # Create optimized tables
                conn.executescript("""
                    CREATE TABLE IF NOT EXISTS documents (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        title TEXT NOT NULL,
                        content TEXT NOT NULL,
                        source TEXT,
                        place_name TEXT,
                        category TEXT DEFAULT 'general',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        content_hash TEXT UNIQUE
                    );
                    
                    CREATE TABLE IF NOT EXISTS user_contributions (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        place_name TEXT NOT NULL,
                        story TEXT NOT NULL,
                        contributor_name TEXT,
                        status TEXT DEFAULT 'pending',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        story_hash TEXT UNIQUE
                    );
                    
                    CREATE INDEX IF NOT EXISTS idx_documents_place ON documents(place_name);
                    CREATE INDEX IF NOT EXISTS idx_documents_category ON documents(category);
                    CREATE INDEX IF NOT EXISTS idx_contributions_place ON user_contributions(place_name);
                    CREATE INDEX IF NOT EXISTS idx_contributions_status ON user_contributions(status);
                """)
                
                conn.commit()
                logging.info("‚úÖ Database initialized successfully")
                
        except Exception as e:
            logging.error(f"‚ùå Database initialization failed: {e}")
    
    def add_document(self, title: str, content: str, source: str = None, 
                    place_name: str = None, category: str = 'general') -> bool:
        """Add document with duplicate prevention"""
        try:
            content_hash = hashlib.md5(content.encode()).hexdigest()
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR IGNORE INTO documents 
                    (title, content, source, place_name, category, content_hash)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (title, content, source, place_name, category, content_hash))
                
                return conn.total_changes > 0
                
        except Exception as e:
            logging.error(f"‚ùå Failed to add document: {e}")
            return False
    
    def add_user_story(self, place_name: str, story: str, 
                      contributor_name: str = None) -> bool:
        """Add user contribution with validation"""
        try:
            story_hash = hashlib.md5(story.encode()).hexdigest()
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR IGNORE INTO user_contributions 
                    (place_name, story, contributor_name, story_hash)
                    VALUES (?, ?, ?, ?)
                """, (place_name, story, contributor_name, story_hash))
                
                return conn.total_changes > 0
                
        except Exception as e:
            logging.error(f"‚ùå Failed to add user story: {e}")
            return False
    
    def get_documents_by_place(self, place_name: str) -> List[Dict]:
        """Get documents filtered by place with caching"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.execute("""
                    SELECT * FROM documents 
                    WHERE place_name LIKE ? 
                    ORDER BY created_at DESC
                """, (f"%{place_name}%",))
                
                return [dict(row) for row in cursor.fetchall()]
                
        except Exception as e:
            logging.error(f"‚ùå Failed to get documents: {e}")
            return []

# Advanced document processor with parallel processing
class OptimizedDocumentProcessor:
    """High-performance document processing with async operations"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    def process_pdf(self, file_bytes: bytes) -> str:
        """Extract text from PDF with error handling"""
        try:
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))
            text_parts = []
            
            for page in pdf_reader.pages:
                text = page.extract_text()
                if text.strip():
                    text_parts.append(text.strip())
            
            return '\n\n'.join(text_parts)
            
        except Exception as e:
            logging.error(f"‚ùå PDF processing failed: {e}")
            return ""
    
    def chunk_text(self, text: str) -> List[str]:
        """Intelligent text chunking with overlap"""
        if len(text) <= config.CHUNK_SIZE:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + config.CHUNK_SIZE
            
            # Find sentence boundary for better chunks
            if end < len(text):
                boundary = text.rfind('.', start, end)
                if boundary > start + config.CHUNK_SIZE // 2:
                    end = boundary + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end - config.CHUNK_OVERLAP
        
        return chunks
    
    def extract_place_names(self, text: str) -> List[str]:
        """Extract Telugu place names using regex patterns"""
        places = set()
        
        for pattern in config.TELUGU_PATTERNS['places']:
            matches = re.findall(pattern, text)
            places.update(matches)
        
        # Clean and filter results
        return list({place.strip() for place in places if len(place.strip()) > 2})

# Advanced Telugu History Bot with optimizations
class ManaCharitra:
    """Main chatbot class with advanced features"""
    
    def __init__(self):
        self.db = OptimizedDatabase()
        self.vector_store = OptimizedVectorStore()
        self.doc_processor = OptimizedDocumentProcessor()
        self.response_cache = SmartCache()
        self._setup_gemini()
        self._load_initial_data()
    
    def _setup_gemini(self) -> None:
        """Configure Gemini API with optimal settings"""
        api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not api_key:
            st.error("‚ö†Ô∏è Gemini API key not found. Please set GEMINI_API_KEY in secrets.")
            return
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
        )
        logging.info("‚úÖ Gemini API configured successfully")
    
    def _load_initial_data(self) -> None:
        """Load initial Telugu historical data"""
        try:
            self.vector_store.load()
            
            # Add default Telugu historical content if vector store is empty
            if self.vector_store.index is None or self.vector_store.index.ntotal == 0:
                default_data = self._get_default_telugu_content()
                self._add_bulk_content(default_data)
            
            logging.info("‚úÖ Initial data loaded successfully")
            
        except Exception as e:
            logging.error(f"‚ùå Failed to load initial data: {e}")
    
    def _get_default_telugu_content(self) -> List[Dict]:
        """Default Telugu historical content for bootstrapping"""
        return [
            {
                "title": "‡∞µ‡∞∞‡∞Ç‡∞ó‡∞≤‡±ç ‡∞ï‡±ã‡∞ü ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞",
                "content": """‡∞µ‡∞∞‡∞Ç‡∞ó‡∞≤‡±ç ‡∞ï‡±ã‡∞ü ‡∞§‡±Ü‡∞≤‡∞Ç‡∞ó‡∞æ‡∞£ ‡∞∞‡∞æ‡∞∑‡±ç‡∞ü‡±ç‡∞∞‡∞Ç‡∞≤‡±ã‡∞®‡∞ø ‡∞µ‡∞∞‡∞Ç‡∞ó‡∞≤‡±ç ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡±ã ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞á‡∞¶‡∞ø ‡∞ï‡∞æ‡∞ï‡∞§‡±Ä‡∞Ø ‡∞∞‡∞æ‡∞ú‡∞µ‡∞Ç‡∞∂‡∞Ç ‡∞ï‡∞æ‡∞≤‡∞Ç‡∞≤‡±ã ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. 
                ‡∞∞‡∞æ‡∞£‡∞ø ‡∞∞‡±Å‡∞¶‡±ç‡∞∞‡∞Æ‡∞æ‡∞¶‡±á‡∞µ‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±ç‡∞∞‡∞§‡∞æ‡∞™‡∞∞‡±Å‡∞¶‡±ç‡∞∞‡±Å‡∞°‡±Å ‡∞ï‡∞æ‡∞≤‡∞Ç‡∞≤‡±ã ‡∞à ‡∞ï‡±ã‡∞ü ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞ø‡∞ö‡±Ü‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞ï‡±ã‡∞ü ‡∞®‡∞ø‡∞∞‡±ç‡∞Æ‡∞æ‡∞£‡∞Ç‡∞≤‡±ã ‡∞ó‡±ç‡∞∞‡∞æ‡∞®‡±à‡∞ü‡±ç ‡∞∞‡∞æ‡∞≥‡±ç‡∞≤‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞æ‡∞∞‡±Å. 
                ‡∞á‡∞¶‡∞ø ‡∞¶‡∞ï‡±ç‡∞∑‡∞ø‡∞£ ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂‡∞Ç‡∞≤‡±ã‡∞®‡∞ø ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞ï‡±ã‡∞ü‡∞≤‡∞≤‡±ã ‡∞í‡∞ï‡∞ü‡∞ø‡∞ó‡∞æ ‡∞™‡∞∞‡∞ø‡∞ó‡∞£‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.""",
                "place_name": "‡∞µ‡∞∞‡∞Ç‡∞ó‡∞≤‡±ç",
                "category": "‡∞ï‡±ã‡∞ü"
            },
            {
                "title": "‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞",
                "content": """‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞µ‡±á‡∞Ç‡∞ï‡∞ü‡±á‡∞∂‡±ç‡∞µ‡∞∞ ‡∞∏‡±ç‡∞µ‡∞æ‡∞Æ‡∞ø ‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç ‡∞Ü‡∞Ç‡∞ß‡±ç‡∞∞‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç ‡∞∞‡∞æ‡∞∑‡±ç‡∞ü‡±ç‡∞∞‡∞Ç‡∞≤‡±ã‡∞®‡∞ø ‡∞ö‡∞ø‡∞§‡±ç‡∞§‡±Ç‡∞∞‡±ç ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡±ã ‡∞â‡∞Ç‡∞¶‡∞ø. 
                ‡∞á‡∞¶‡∞ø ‡∞µ‡±á‡∞Ç‡∞ï‡∞ü‡∞æ‡∞¶‡±ç‡∞∞‡∞ø ‡∞™‡∞∞‡±ç‡∞µ‡∞§‡∞Ç‡∞™‡±à ‡∞∏‡±ç‡∞•‡∞ø‡∞§‡∞ø‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞à ‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç ‡∞µ‡±á‡∞≤‡∞æ‡∞¶‡∞ø ‡∞∏‡∞Ç‡∞µ‡∞§‡±ç‡∞∏‡∞∞‡∞æ‡∞≤ ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞‡∞®‡±Å ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø ‡∞â‡∞Ç‡∞¶‡∞ø. 
                ‡∞™‡∞≤‡±ç‡∞≤‡∞µ, ‡∞ö‡±ã‡∞≥, ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞®‡∞ó‡∞∞ ‡∞∞‡∞æ‡∞ú‡∞µ‡∞Ç‡∞∂‡∞æ‡∞≤ ‡∞ï‡∞æ‡∞≤‡∞Ç‡∞≤‡±ã ‡∞à ‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç ‡∞Ö‡∞≠‡∞ø‡∞µ‡±É‡∞¶‡±ç‡∞ß‡∞ø ‡∞ö‡±Ü‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∞‡±ã‡∞ú‡±Ç ‡∞≤‡∞ï‡±ç‡∞∑‡∞≤‡∞æ‡∞¶‡∞ø ‡∞Æ‡∞Ç‡∞¶‡∞ø ‡∞≠‡∞ï‡±ç‡∞§‡±Å‡∞≤‡±Å ‡∞¶‡∞∞‡±ç‡∞∂‡∞®‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞µ‡∞∏‡±ç‡∞§‡∞æ‡∞∞‡±Å.""",
                "place_name": "‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤",
                "category": "‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø‡∞Ç"
            }
        ]
    
    def _add_bulk_content(self, content_list: List[Dict]) -> None:
        """Add multiple content items efficiently"""
        texts = []
        metadata = []
        
        for item in content_list:
            # Add to database
            self.db.add_document(
                title=item["title"],
                content=item["content"],
                place_name=item["place_name"],
                category=item.get("category", "general")
            )
            
            # Prepare for vector store
            texts.append(item["content"])
            metadata.append({
                "text": item["content"],
                "title": item["title"],
                "place_name": item["place_name"],
                "category": item.get("category", "general")
            })
        
        # Add to vector store in batch
        self.vector_store.add_documents(texts, metadata)
        self.vector_store.save()
    
    def chat(self, user_query: str) -> str:
        """Main chat function with caching and optimization"""
        # Check cache first
        cache_key = hashlib.md5(user_query.encode()).hexdigest()
        cached_response = self.response_cache.get(cache_key)
        if cached_response:
            return cached_response
        
        try:
            # Search for relevant content
            search_results = self.vector_store.search(user_query, k=3)
            
            # Build context from search results
            context = self._build_context(search_results)
            
            # Generate response using Gemini
            response = self._generate_response(user_query, context)
            
            # Cache the response
            self.response_cache.set(cache_key, response)
            
            return response
            
        except Exception as e:
            logging.error(f"‚ùå Chat failed: {e}")
            return "‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞™‡±ç‡∞∞‡∞∏‡±ç‡∞§‡±Å‡∞§‡∞Ç ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞é‡∞¶‡±Å‡∞∞‡±ç‡∞ï‡±ä‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø."
    
    def _build_context(self, search_results: List[Tuple]) -> str:
        """Build context from search results"""
        if not search_results:
            return "‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞¶‡±ä‡∞∞‡∞ï‡∞≤‡±á‡∞¶‡±Å."
        
        context_parts = []
        for text, score, metadata in search_results:
            if score > 0.5:  # Relevance threshold
                context_parts.append(f"**{metadata['title']}**\n{text}")
        
        return "\n\n".join(context_parts[:3])  # Top 3 results
    
    def _generate_response(self, query: str, context: str) -> str:
        """Generate response using Gemini with Telugu optimization"""
        prompt = f"""
        ‡∞Æ‡±Ä‡∞∞‡±Å "‡∞Æ‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞" ‡∞Ö‡∞®‡±á ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞ö‡∞æ‡∞ü‡±ç‚Äå‡∞¨‡∞æ‡∞ü‡±ç. ‡∞Æ‡±Ä ‡∞™‡∞®‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞æ‡∞≤ ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡∞æ‡∞Ç‡∞∏‡±ç‡∞ï‡±É‡∞§‡∞ø‡∞ï ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç.

        ‡∞®‡∞ø‡∞Ø‡∞Æ‡∞æ‡∞≤‡±Å:
        1. ‡∞é‡∞≤‡±ç‡∞≤‡∞™‡±ç‡∞™‡±Å‡∞°‡±Ç ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞ú‡∞µ‡∞æ‡∞¨‡±Å ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø
        2. ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞, ‡∞∏‡∞Ç‡∞∏‡±ç‡∞ï‡±É‡∞§‡∞ø ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ü‡∞∏‡∞ï‡±ç‡∞§‡∞ø‡∞ï‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø
        3. ‡∞µ‡∞æ‡∞∏‡±ç‡∞§‡∞µ‡∞ø‡∞ï ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞Ö‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
        4. ‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞®‡∞ø ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞æ‡∞≤ ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞ä‡∞π‡∞≤‡±Å ‡∞ö‡±á‡∞Ø‡∞µ‡∞¶‡±ç‡∞¶‡±Å

        ‡∞∏‡∞Ç‡∞¶‡∞∞‡±ç‡∞≠ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç:
        {context}

        ‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞¶‡∞æ‡∞∞‡±Å ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®: {query}

        ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞æ‡∞§‡±ç‡∞Æ‡∞ï ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Ü‡∞∏‡∞ï‡±ç‡∞§‡∞ø‡∞ï‡∞∞‡∞Æ‡±à‡∞® ‡∞ú‡∞µ‡∞æ‡∞¨‡±Å ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø:
        """
        
        try:
            response = self.model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            logging.error(f"‚ùå Response generation failed: {e}")
            return "‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞™‡±ç‡∞∞‡∞∏‡±ç‡∞§‡±Å‡∞§‡∞Ç ‡∞ú‡∞µ‡∞æ‡∞¨‡±Å ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞é‡∞¶‡±Å‡∞∞‡±ç‡∞ï‡±ä‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å."
    
    def add_document_from_file(self, uploaded_file) -> bool:
        """Process uploaded file and add to knowledge base"""
        try:
            # Extract text from file
            if uploaded_file.type == "application/pdf":
                text = self.doc_processor.process_pdf(uploaded_file.getvalue())
            else:
                text = uploaded_file.getvalue().decode('utf-8')
            
            if not text.strip():
                return False
            
            # Extract place names
            places = self.doc_processor.extract_place_names(text)
            place_name = places[0] if places else "‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£"
            
            # Chunk text for better processing
            chunks = self.doc_processor.chunk_text(text)
            
            # Add to database and vector store
            success_count = 0
            for i, chunk in enumerate(chunks):
                title = f"{uploaded_file.name} - ‡∞≠‡∞æ‡∞ó‡∞Ç {i+1}"
                
                if self.db.add_document(title, chunk, uploaded_file.name, place_name):
                    success_count += 1
            
            # Add to vector store
            if chunks:
                metadata = [{
                    "text": chunk,
                    "title": f"{uploaded_file.name} - ‡∞≠‡∞æ‡∞ó‡∞Ç {i+1}",
                    "place_name": place_name,
                    "category": "user_upload"
                } for i, chunk in enumerate(chunks)]
                
                self.vector_store.add_documents(chunks, metadata)
                self.vector_store.save()
            
            return success_count > 0
            
        except Exception as e:
            logging.error(f"‚ùå File processing failed: {e}")
            return False
    
    def add_user_story(self, place_name: str, story: str, 
                      contributor_name: str = None) -> bool:
        """Add user story to knowledge base"""
        try:
            # Add to database
            db_success = self.db.add_user_story(place_name, story, contributor_name)
            
            # Add to vector store
            metadata = [{
                "text": story,
                "title": f"{place_name} - ‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞¶‡∞æ‡∞∞‡±Å ‡∞ï‡∞•",
                "place_name": place_name,
                "category": "user_story"
            }]
            
            self.vector_store.add_documents([story], metadata)
            self.vector_store.save()
            
            return db_success
            
        except Exception as e:
            logging.error(f"‚ùå Failed to add user story: {e}")
            return False

# Initialize logging
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(levelname)s - %(message)s')

# Streamlit UI with advanced features
def main():
    """Main Streamlit application with optimized UI"""
    
    st.set_page_config(
        page_title="‡∞Æ‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ - Mana Charitra",
        page_icon="üìö",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Custom CSS for Telugu fonts and styling
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Telugu:wght@300;400;500;700&display=swap');
    
    .main-title {
        font-family: 'Noto Sans Telugu', sans-serif;
        text-align: center;
        color: #2E8B57;
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 1rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    .telugu-text {
        font-family: 'Noto Sans Telugu', sans-serif;
        font-size: 1.1rem;
        line-height: 1.6;
    }
    
    .chat-container {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
    }
    
    .user-message {
        background: #e3f2fd;
        border-left: 4px solid #2196f3;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    .bot-message {
        background: #f3e5f5;
        border-left: 4px solid #9c27b0;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    .stats-card {
        background: white;
        border-radius: 10px;
        padding: 15px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Initialize session state
    if 'chatbot' not in st.session_state:
        with st.spinner('üîÑ ‡∞Æ‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞≤‡±ã‡∞°‡±ç ‡∞Ö‡∞µ‡±Å‡∞§‡±ã‡∞Ç‡∞¶‡∞ø...'):
            st.session_state.chatbot = ManaCharitra()
            st.success('‚úÖ ‡∞Æ‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞∏‡∞ø‡∞¶‡±ç‡∞ß‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø!')
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # Main title
    st.markdown('<h1 class="main-title">üìö ‡∞Æ‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ - Mana Charitra üìö</h1>', 
                unsafe_allow_html=True)
    
    st.markdown('<p class="telugu-text" style="text-align: center; font-size: 1.2rem; color: #666;">‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞æ‡∞≤ ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡∞æ‡∞Ç‡∞∏‡±ç‡∞ï‡±É‡∞§‡∞ø‡∞ï ‡∞µ‡±à‡∞≠‡∞µ‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø</p>', 
                unsafe_allow_html=True)
    
    # Sidebar with features
    with st.sidebar:
        st.markdown("### üéØ ‡∞´‡±Ä‡∞ö‡∞∞‡±ç‡∞≤‡±Å")
        
        selected_tab = st.radio(
            "‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø:",
            ["üí¨ ‡∞ö‡∞æ‡∞ü‡±ç", "üì§ ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞Ö‡∞™‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç", "‚úçÔ∏è ‡∞Æ‡±Ä ‡∞ï‡∞•", "üìä ‡∞ó‡∞£‡∞æ‡∞Ç‡∞ï‡∞æ‡∞≤‡±Å"],
            index=0
        )
        
        st.markdown("---")
        st.markdown("### üí° ‡∞â‡∞¶‡∞æ‡∞π‡∞∞‡∞£ ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡±Å")
        example_questions = [
            "‡∞µ‡∞∞‡∞Ç‡∞ó‡∞≤‡±ç ‡∞ï‡±ã‡∞ü ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø",
            "‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤ ‡∞¶‡±á‡∞µ‡∞æ‡∞≤‡∞Ø ‡∞™‡±ç‡∞∞‡∞æ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞§ ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
            "‡∞ï‡∞æ‡∞ï‡∞§‡±Ä‡∞Ø ‡∞∞‡∞æ‡∞ú‡∞µ‡∞Ç‡∞∂‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞ú‡±á‡∞Ø‡∞Ç‡∞°‡∞ø",
            "‡∞π‡±à‡∞¶‡∞∞‡∞æ‡∞¨‡∞æ‡∞¶‡±ç ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø"
        ]
        
        for question in example_questions:
            if st.button(question, key=f"ex_{hash(question)}"):
                st.session_state.user_input = question
    
    # Main content area
    if selected_tab == "üí¨ ‡∞ö‡∞æ‡∞ü‡±ç":
        render_chat_interface()
    elif selected_tab == "üì§ ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞Ö‡∞™‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç":
        render_upload_interface()
    elif selected_tab == "‚úçÔ∏è ‡∞Æ‡±Ä ‡∞ï‡∞•":
        render_story_interface()
    elif selected_tab == "üìä ‡∞ó‡∞£‡∞æ‡∞Ç‡∞ï‡∞æ‡∞≤‡±Å":
        render_stats_interface()

def render_chat_interface():
    """Render the main chat interface"""
    st.markdown("### üí¨ ‡∞Æ‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞‡∞§‡±ã ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞Ç‡∞°‡∞ø")
    
    # Chat history display
    chat_container = st.container()
    
    with chat_container:
        if st.session_state.chat_history:
            for i, (user_msg, bot_msg) in enumerate(st.session_state.chat_history):
                st.markdown(f'<div class="user-message telugu-text"><strong>‡∞Æ‡±Ä‡∞∞‡±Å:</strong> {user_msg}</div>', 
                           unsafe_allow_html=True)
                st.markdown(f'<div class="bot-message telugu-text"><strong>‡∞Æ‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞:</strong> {bot_msg}</div>', 
                           unsafe_allow_html=True)
        else:
            st.markdown('<div class="telugu-text" style="text-align: center; color: #666; padding: 20px;">‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç! ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞æ‡∞≤ ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞è‡∞¶‡±à‡∞®‡∞æ ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø...</div>', 
                       unsafe_allow_html=True)
    
    # Chat input
    col1, col2 = st.columns([4, 1])
    
    with col1:
        user_input = st.text_input(
            "‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ü‡±à‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø:",
            value=st.session_state.get('user_input', ''),
            placeholder="‡∞â‡∞¶‡∞æ: ‡∞µ‡∞∞‡∞Ç‡∞ó‡∞≤‡±ç ‡∞ï‡±ã‡∞ü ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø",
            key="chat_input"
        )
    
    with col2:
        send_button = st.button("üì§ ‡∞™‡∞Ç‡∞™‡∞Ç‡∞°‡∞ø", type="primary")
    
    # Process user input
    if (send_button and user_input.strip()) or st.session_state.get('user_input'):
        if st.session_state.get('user_input'):
            user_input = st.session_state.user_input
            st.session_state.user_input = ""
        
        with st.spinner('ü§î ‡∞Ü‡∞≤‡±ã‡∞ö‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å...'):
            response = st.session_state.chatbot.chat(user_input)
            st.session_state.chat_history.append((user_input, response))
            st.rerun()

def render_upload_interface():
    """Render file upload interface"""
    st.markdown("### üì§ ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞Ö‡∞™‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø")
    
    st.markdown('<div class="telugu-text">‡∞Æ‡±Ä ‡∞¶‡∞ó‡±ç‡∞ó‡∞∞ ‡∞â‡∞®‡±ç‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞æ‡∞≤‡∞®‡±Å (PDF, ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç) ‡∞Ö‡∞™‡±ç‚Äå‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞ ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç‚Äå‡∞®‡±Å ‡∞∏‡∞Æ‡±É‡∞¶‡±ç‡∞ß‡∞ø‡∞ó‡∞æ ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.</div>', 
                unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader(
        "‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø:",
        type=['pdf', 'txt'],
        help="PDF ‡∞≤‡±á‡∞¶‡∞æ ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞´‡±à‡∞≤‡±ç‡∞∏‡±ç ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á"
    )
    
    if uploaded_file is not None:
        st.success(f"‚úÖ ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞é‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø: {uploaded_file.name}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info(f"üìÅ ‡∞´‡±à‡∞≤‡±ç ‡∞∞‡∞ï‡∞Ç: {uploaded_file.type}")
        
        with col2:
            st.info(f"üìè ‡∞´‡±à‡∞≤‡±ç ‡∞™‡∞∞‡∞ø‡∞Æ‡∞æ‡∞£‡∞Ç: {uploaded_file.size / 1024:.1f} KB")
        
        if st.button("üîÑ ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø", type="primary"):
            with st.spinner('üìñ ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞ö‡∞¶‡±Å‡∞µ‡±Å‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å...'):
                success = st.session_state.chatbot.add_document_from_file(uploaded_file)
                
                if success:
                    st.success("‚úÖ ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø!")
                    st.balloons()
                else:
                    st.error("‚ùå ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞Ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞é‡∞¶‡±Å‡∞∞‡±à‡∞Ç‡∞¶‡∞ø")

def render_story_interface():
    """Render user story contribution interface"""
    st.markdown("### ‚úçÔ∏è ‡∞Æ‡±Ä ‡∞ï‡∞• ‡∞™‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø")
    
    st.markdown('<div class="telugu-text">‡∞Æ‡±Ä ‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç ‡∞≤‡±á‡∞¶‡∞æ ‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞§‡±Ü‡∞≤‡∞ø‡∞∏‡∞ø‡∞® ‡∞ï‡∞•‡∞≤‡±Å, ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞, ‡∞≤‡±á‡∞¶‡∞æ ‡∞™‡±Å‡∞∞‡∞æ‡∞£‡∞æ‡∞≤‡∞®‡±Å ‡∞™‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø.</div>', 
                unsafe_allow_html=True)
    
    with st.form("story_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            place_name = st.text_input(
                "‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞Ç/‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç ‡∞™‡±á‡∞∞‡±Å:",
                placeholder="‡∞â‡∞¶‡∞æ: ‡∞µ‡∞∞‡∞Ç‡∞ó‡∞≤‡±ç, ‡∞§‡∞ø‡∞∞‡±Å‡∞Æ‡∞≤"
            )
        
        with col2:
            contributor_name = st.text_input(
                "‡∞Æ‡±Ä ‡∞™‡±á‡∞∞‡±Å (‡∞ê‡∞ö‡±ç‡∞õ‡∞ø‡∞ï‡∞Ç):",
                placeholder="‡∞Æ‡±Ä ‡∞™‡±á‡∞∞‡±Å"
            )
        
        story = st.text_area(
            "‡∞Æ‡±Ä ‡∞ï‡∞•/‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞:",
            height=200,
            placeholder="‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞ö‡∞∞‡∞ø‡∞§‡±ç‡∞∞, ‡∞ï‡∞•‡∞≤‡±Å, ‡∞™‡±Å‡∞∞‡∞æ‡∞£‡∞æ‡∞≤‡∞®‡±Å ‡∞µ‡±ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø...",
            help="‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞µ‡∞æ‡∞∏‡±ç‡∞§‡∞µ‡∞ø‡∞ï ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞™‡∞Ç‡∞ö‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø"
        )
        
        submitted = st.form_submit_button("üìù ‡∞ï‡∞• ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø", type="primary")
        
        if submitted:
            if place_name.strip() and story.strip():
                with st.spinner('üíæ ‡∞ï‡∞• ‡∞∏‡±á‡∞µ‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å...'):
                    success = st.session_state.chatbot.add_user_story(
                        place_name.strip(), 
                        story.strip(), 
                        contributor_name.strip() or None
                    )
                    
                    if success:
                        st.success("‚úÖ ‡∞Æ‡±Ä ‡∞ï‡∞• ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø! ‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å!")
                        st.balloons()
                    else:
                        st.warning("‚ö†Ô∏è ‡∞à ‡∞ï‡∞• ‡∞á‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±á ‡∞â‡∞Ç‡∞¶‡∞ø ‡∞≤‡±á‡∞¶‡∞æ ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞é‡∞¶‡±Å‡∞∞‡±à‡∞Ç‡∞¶‡∞ø")
            else:
                st.error("‚ùå ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞Ç ‡∞™‡±á‡∞∞‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ï‡∞• ‡∞∞‡±Ü‡∞Ç‡∞°‡±Ç ‡∞µ‡±ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø")

def render_stats_interface():
    """Render statistics and analytics interface"""
    st.markdown("### üìä ‡∞ó‡∞£‡∞æ‡∞Ç‡∞ï‡∞æ‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡∞ø‡∞∂‡±ç‡∞≤‡±á‡∞∑‡∞£")
    
    # Get statistics from database
    db = st.session_state.chatbot.db
    
    try:
        with sqlite3.connect(db.db_path) as conn:
            # Total documents
            cursor = conn.execute("SELECT COUNT(*) FROM documents")
            total_docs = cursor.fetchone()[0]
            
            # Total user contributions
            cursor = conn.execute("SELECT COUNT(*) FROM user_contributions")
            total_contributions = cursor.fetchone()[0]
            
            # Popular places
            cursor = conn.execute("""
                SELECT place_name, COUNT(*) as count 
                FROM documents 
                WHERE place_name IS NOT NULL 
                GROUP BY place_name 
                ORDER BY count DESC 
                LIMIT 10
            """)
            popular_places = cursor.fetchall()
            
            # Recent additions
            cursor = conn.execute("""
                SELECT title, place_name, created_at 
                FROM documents 
                ORDER BY created_at DESC 
                LIMIT 5
            """)
            recent_docs = cursor.fetchall()
    
    except Exception as e:
        st.error(f"‡∞ó‡∞£‡∞æ‡∞Ç‡∞ï‡∞æ‡∞≤‡±Å ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø: {e}")
        return
    
    # Display statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="stats-card">
            <h3 style="color: #2E8B57;">üìö</h3>
            <h2>{total_docs}</h2>
            <p>‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞æ‡∞≤‡±Å</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="stats-card">
            <h3 style="color: #FF6B6B;">‚úçÔ∏è</h3>
            <h2>{total_contributions}</h2>
            <p>‡∞µ‡∞ø‡∞®‡∞ø‡∞Ø‡±ã‡∞ó‡∞¶‡∞æ‡∞∞‡±Å ‡∞ï‡∞•‡∞≤‡±Å</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        vector_count = st.session_state.chatbot.vector_store.index.ntotal if st.session_state.chatbot.vector_store.index else 0
        st.markdown(f"""
        <div class="stats-card">
            <h3 style="color: #4ECDC4;">üîç</h3>
            <h2>{vector_count}</h2>
            <p>‡∞µ‡±Ü‡∞ï‡±ç‡∞ü‡∞∞‡±ç ‡∞é‡∞Ç‡∞ü‡±ç‡∞∞‡±Ä‡∞≤‡±Å</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="stats-card">
            <h3 style="color: #45B7D1;">üó∫Ô∏è</h3>
            <h2>{len(popular_places)}</h2>
            <p>‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞æ‡∞≤‡±Å</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Popular places chart
    if popular_places:
        st.markdown("### üèÜ ‡∞™‡±ç‡∞∞‡∞∏‡∞ø‡∞¶‡±ç‡∞ß ‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞æ‡∞≤‡±Å")
        
        places_df = pd.DataFrame(popular_places, columns=['‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞Ç', '‡∞¶‡∞∏‡±ç‡∞§‡±ç‡∞∞‡∞æ‡∞≤ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø'])
        st.bar_chart(places_df.set_index('‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞Ç'))
    
    # Recent additions
    if recent_docs:
        st.markdown("### üÜï ‡∞á‡∞ü‡±Ä‡∞µ‡∞≤‡∞ø ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞™‡±Å‡∞≤‡±Å")
        
        for title, place, created_at in recent_docs:
            with st.expander(f"üìñ {title}"):
                st.markdown(f"**‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞§‡∞Ç:** {place or '‡∞∏‡∞æ‡∞ß‡∞æ‡∞∞‡∞£'}")
                st.markdown(f"**‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞§‡±á‡∞¶‡±Ä:** {created_at}")

if __name__ == "__main__":
    main()